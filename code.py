# -*- coding: utf-8 -*-
"""Assignment 3 - Alif

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nX4RHH0WFderx9QKDrHxXPxwy1UchOw5

AES TOEFL
"""

import nltk
nltk.download('stopwords')

print('nltk version:', nltk.__version__)
!python --version

"""Step 1: Load Data
(low, medium, high)
"""

import pandas as pd

# Load your dataset (update 'file.csv' with your actual file path)
data = pd.read_csv("ETS_corpus_F24.csv")

# Display the first few rows
print(data.head())

"""Step 2: Pre-process Data

2.1 Text Cleaning
"""

def clean_text_file(filepath):
  """
  Opens a .txt file, tokenizes it, removes punctuation (excluding apostrophes within words), and returns the cleaned text.
  NOTE: A filepath is differnt from a directory. A filepath points to a file. A directory path points to a folder.

  Args:
    filepath: The path to the .txt file.

  Returns:
    A string containing the cleaned text.
  """
  with open(filepath, 'r') as file:
    text = file.read()
    # print(text)

  # Lowercase the text and Tokenize the text (split into words)
  tokens = text.lower().split()

   # Remove punctuation tokens
  cleaned_tokens = [token for token in tokens if token.isalnum()]

  # Join the cleaned tokens back into a string
  cleaned_text = ' '.join(cleaned_tokens)

  return cleaned_text

# prompt: print the text from the previous cell

import nltk
import pandas as pd
# AES TOEFL
nltk.download('stopwords')

print('nltk version:', nltk.__version__)
!python --version
# Step 1: Load Data
# (low, medium, high)

# Load your dataset (update 'file.csv' with your actual file path)
data = pd.read_csv("ETS_corpus_F24.csv")

# Display the first few rows
print(data.head())

# Step 2: Pre-process Data
# Text Cleaning
def clean_text_file(filepath):
  """
  Opens a .txt file, tokenizes it, removes punctuation (excluding apostrophes within words), and returns the cleaned text.
  NOTE: A filepath is differnt from a directory. A filepath points to a file. A directory path points to a folder.

  Args:
    filepath: The path to the .txt file.

  Returns:
    A string containing the cleaned text.
  """
  with open(filepath, 'r') as file:
    text = file.read()
    # print(text)

  # Lowercase the text and Tokenize the text (split into words)
  tokens = text.lower().split()

   # Remove punctuation tokens
  cleaned_tokens = [token for token in tokens if token.isalnum()]

  # Join the cleaned tokens back into a string
  cleaned_text = ' '.join(cleaned_tokens)

  return cleaned_text

import nltk
import pandas as pd

# Download NLTK stopwords if needed
nltk.download('stopwords')

# Load the dataset (replace with the actual file path)
data = pd.read_csv("ETS_corpus_F24.csv")

# Display the first few rows to understand the structure
print(data.head())

# Function to clean text
def clean_text(text):
    """
    Cleans the input text by lowercasing, tokenizing, and removing punctuation.

    Args:
        text: The input text as a string.

    Returns:
        Cleaned text as a string.
    """
    tokens = text.lower().split()
    cleaned_tokens = [token for token in tokens if token.isalnum()]
    cleaned_text = ' '.join(cleaned_tokens)
    return cleaned_text

# Apply text cleaning to the dataset
data['Cleaned_Text'] = data['text'].apply(clean_text)

# Calculate word count for each cleaned text
data['Word_Count'] = data['Cleaned_Text'].apply(lambda x: len(x.split()))

# Group by level and compute statistics
stats = data.groupby('level')['Word_Count'].agg(['count', 'mean', 'std', 'min', 'max']).reset_index()

# Display the statistics
print(stats)

# Save statistics to a CSV file
stats.to_csv("word_count_statistics.csv", index=False)

# prompt: calculate the total word counts for the table above

import pandas as pd

# Load the dataset
data = pd.read_csv("word_count_statistics.csv")

# Calculate the total word count
total_word_count = data['count'].sum()

# Print the total word count
print(f"Total word count: {total_word_count}")

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset (replace with actual file path)
data = pd.read_csv("ETS_corpus_F24.csv")

# Calculate class distribution
class_distribution = data['level'].value_counts()

# Print the class distribution
print("Class Distribution:")
print(class_distribution)

# Visualize the class distribution
class_distribution.plot(kind='bar')
plt.title('Class Distribution')
plt.xlabel('Level')
plt.ylabel('Count')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset (replace with actual file path)
data = pd.read_csv("ETS_corpus_F24.csv")

# Assuming 'level' column represents language distribution
language_distribution = data['level'].value_counts() # Assign language_distribution

# Calculate standard deviation for language distribution
language_std = language_distribution.std()
print("Standard Deviation of Language Distribution:", language_std)

# prompt: find the balance of the data

# Calculate class distribution
class_distribution = data['level'].value_counts(normalize=True) * 100

# Print the class distribution percentages
print("Class Distribution (Percentage):")
print(class_distribution)

# Visualize the class distribution
class_distribution.plot(kind='bar')
plt.title('Class Distribution (%)')
plt.xlabel('Level')
plt.ylabel('Percentage')
plt.show()

"""balance the dataset"""

import pandas as pd

# Load the dataset
df = pd.read_csv('ETS_corpus_F24.csv')

# Check class distribution
print("Class distribution before balancing:")
print(df['level'].value_counts())

# Find the minimum count of samples among the classes
min_class_count = df['level'].value_counts().min()

# Balance the dataset by sampling `min_class_count` samples from each class
balanced_df = df.groupby('level').apply(lambda x: x.sample(min_class_count)).reset_index(drop=True)

# Check the class distribution after balancing
print("\nClass distribution after balancing:")
print(balanced_df['level'].value_counts())

# Save the balanced dataset if needed
balanced_df.to_csv('balanced_ETS_corpus_F24.csv', index=False)

"""2.2 CVA features

2.2.1 Classification with TF-IDF and Text-Length
"""

import pandas as pd
import string
import time
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# time your pipeline and workflow
# Record start time
start_time = time.time()

# Load your balanced dataset
df = pd.read_csv('ETS_corpus_F24.csv')


# Functions to calculate linguistic features: text length and punctuation percentage
def text_length(text):
    '''calculate the length of a response in characters '''
    return len(text)

# Apply the function to the DataFrame
df['text_length'] = df['text'].apply(text_length)

# Separate features and labels
X = df[['text', 'text_length']]
y = df['level']  # 'level' is the target variable

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a ColumnTransformer and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text'),
        ('num', StandardScaler(), ['text_length'])
    ])

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear'))
])



# Train the model
pipeline.fit(X_train, y_train)

# Predict and evaluate the model
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

# Define label order explicitly
label_order = ['high', 'medium', 'low']

# Display the confusion matrix and classification report
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("Confusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Record end time
end_time = time.time()

# Calculate execution time
execution_time = end_time - start_time
print(f"Execution time: {execution_time} seconds")

import pandas as pd
import string
import time
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# Load your balanced dataset
df = pd.read_csv('ETS_corpus_F24.csv')

# Functions to calculate linguistic features
def text_length(text):
    return len(text)

# Apply the function to the DataFrame
df['text_length'] = df['text'].apply(text_length)

# Separate features and labels
X = df[['text', 'text_length']]
y = df['level']

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a ColumnTransformer and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text'),
        ('num', StandardScaler(), ['text_length'])
    ])

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear'))
])

# Train the model
pipeline.fit(X_train, y_train)

# Predict and evaluate the model
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

# Define label order explicitly
label_order = ['high', 'medium', 'low']

# Display the confusion matrix and classification report
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("\nClassification Report:\n", class_report)

# Create a confusion matrix DataFrame
conf_matrix_df = pd.DataFrame(conf_matrix, index=label_order, columns=label_order)

# Print confusion matrix as a table
print("\nConfusion Matrix Table:")
print(conf_matrix_df)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_df, annot=True, cmap="Blues", fmt="d", cbar=False)
plt.title("Confusion Matrix")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

# prompt: calculate the QWK for the cell above

from sklearn.metrics import cohen_kappa_score

# Assuming 'predictions' and 'y_test' are already defined from the previous code

# Calculate QWK
qwk = cohen_kappa_score(y_test, predictions, weights='quadratic')
print(f"Quadratic Weighted Kappa (QWK): {qwk}")

"""2.2.2 Classification with TF-IDF and lexical analysis feature 1 (HDD)"""

import os
import nltk
import pandas as pd
import string
import time
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# Download nltk resources
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('punkt_tab')

stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# Record start time
start_time = time.time()



# Define text cleaning function
def clean_text(text):
    text = "".join([char.lower() for char in text if char not in string.punctuation])
    tokens = re.split('\W+', text)
    text = [ps.stem(word) for word in tokens if word not in stopwords]
    return " ".join(text)

# Add linguistic features
df['text_length'] = df['text'].apply(lambda x: len(x.split()))
df['tf_text'] = df['text'].apply(clean_text)

# Define calculate_hdd
def calculate_hdd(tokens):
    return len(set(tokens)) / len(tokens) if tokens else 0

df['text_HDD'] = df['text'].apply(lambda x: calculate_hdd(nltk.word_tokenize(clean_text(x))))

# Separate features and labels
X = df[['tf_text', 'text_length']]
y = df['level']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessor and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'tf_text'),
        ('num', 'passthrough', ['text_length'])
    ]
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced'))
])

# Train the model
pipeline.fit(X_train, y_train)

# Evaluate the model
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

label_order = ['high', 'medium', 'low']
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order)

print("Confusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Execution time
execution_time = time.time() - start_time
print(f"Execution time: {execution_time:.2f} seconds")

import pandas as pd
import string
import time
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# time your pipeline and workflow
# Record start time
start_time = time.time()

# Load your balanced dataset
df = pd.read_csv('ETS_corpus_F24.csv')


# Functions to calculate linguistic features: text length and punctuation percentage
def text_length(text):
    '''calculate the length of a response in characters '''
    return len(text)

# Apply the function to the DataFrame
df['text_length'] = df['text'].apply(text_length)

# Separate features and labels
X = df[['text', 'text_length']]
y = df['level']  # 'level' is the target variable

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a ColumnTransformer and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text'),
        ('num', StandardScaler(), ['text_length'])
    ])

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear'))
])



# Train the model
pipeline.fit(X_train, y_train)

# Predict and evaluate the model
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

# Define label order explicitly
label_order = ['high', 'medium', 'low']

# Display the confusion matrix and classification report
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("Confusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Record end time
end_time = time.time()

# Calculate execution time
execution_time = end_time - start_time
print(f"Execution time: {execution_time} seconds")

# prompt: calculate QWK for the cell above

# Assuming 'predictions' and 'y_test' are already defined from the previous code

# Calculate QWK
qwk = cohen_kappa_score(y_test, predictions, weights='quadratic')
print(f"Quadratic Weighted Kappa (QWK): {qwk}")

"""2.2.3 Classification with TF-IDF and lexical analysis feature 1 (Yule's K)"""

import os
import nltk
import pandas as pd
import string
import time
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# Download nltk resources
nltk.download('stopwords')
nltk.download('punkt')

stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# Record start time
start_time = time.time()


# Define text cleaning function
def clean_text(text):
    text = "".join([char.lower() for char in text if char not in string.punctuation])
    tokens = re.split('\W+', text)
    tokens = [ps.stem(word) for word in tokens if word not in stopwords]
    return " ".join(tokens)

# Calculate Yule's K
def calculate_yule_k(tokens):
    if not tokens:
        return 0
    freq_dist = nltk.FreqDist(tokens)
    n = sum(freq_dist.values())
    s1 = sum(f ** 2 for f in freq_dist.values())
    return (s1 - n) / (n ** 2) if n > 0 else 0

# Add linguistic features
df['tf_text'] = df['text'].apply(clean_text)
df['text_length'] = df['text'].apply(lambda x: len(x.split()))
df['yule_k'] = df['text'].apply(lambda x: calculate_yule_k(nltk.word_tokenize(clean_text(x))))

# Separate features and labels
X = df[['tf_text', 'text_length']]
y = df['level']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessor and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'tf_text'),
        ('num', 'passthrough', ['text_length'])
    ]
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced'))
])

# Train the model
pipeline.fit(X_train, y_train)

# Evaluate the model
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

label_order = ['high', 'medium', 'low']
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order)

print("Confusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Execution time
execution_time = time.time() - start_time
print(f"Execution time: {execution_time:.2f} seconds")

import pandas as pd
import string
import time
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# time your pipeline and workflow
# Record start time
start_time = time.time()

# Load your balanced dataset
df = pd.read_csv('balanced_ETS_corpus_F24.csv')


# Functions to calculate linguistic features: text length and punctuation percentage
def text_length(text):
    '''calculate the length of a response in characters '''
    return len(text)

# Apply the function to the DataFrame
df['text_length'] = df['text'].apply(text_length)

# Separate features and labels
X = df[['text', 'text_length']]
y = df['level']  # 'level' is the target variable

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a ColumnTransformer and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text'),
        ('num', StandardScaler(), ['text_length'])
    ])

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear'))
])



# Train the model
pipeline.fit(X_train, y_train)

# Predict and evaluate the model
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

# Define label order explicitly
label_order = ['high', 'medium', 'low']

# Display the confusion matrix and classification report
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("Confusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Record end time
end_time = time.time()

# Calculate execution time
execution_time = end_time - start_time
print(f"Execution time: {execution_time} seconds")

# prompt: calculate the kappa above

from sklearn.metrics import cohen_kappa_score

# Assuming 'predictions' and 'y_test' are already defined from the previous code

# Calculate QWK
qwk = cohen_kappa_score(y_test, predictions, weights='quadratic')
print(f"Quadratic Weighted Kappa (QWK): {qwk}")

"""2.2.5 Classification with TF-IDF and error passive voice"""

!pip install spacy nltk
import spacy
from spacy.matcher import Matcher
import pandas as pd
import string
import time
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# Download nltk resources
nltk.download('stopwords')
nltk.download('punkt')

stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Define the error detection function
def error(text):
    if not text:  # Handle empty or None text
        return 0

    doc = nlp(text)
    matcher = Matcher(nlp.vocab)
    pattern = [
        {"POS": {"in": ["AUX"]}, "LEMMA": {"in": ["will", "would", "can", "could", "may", "might", "must", "shall", "should"]}, "OP": "?"},
        {"POS": {"in": ["AUX"]}, "LEMMA": {"in": ["be", "am", "is", "are", "was", "were", "been"]}},
        {"POS": "ADV", "OP": "?"},
        {"TAG": "VBN"}
    ]
    matcher.add("PassiveVoice", [pattern])
    matches = matcher(doc)
    return len(matches)

# Load dataset
df = pd.read_csv('ETS_corpus_F24.csv')

# Apply error detection
df['text_error'] = df['text'].apply(error)

# Separate features and labels
X = df[['text', 'text_error']]
y = df['level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessor and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text'),
        ('scaler', StandardScaler(), ['text_error'])
    ]
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced'))
])

# Train the pipeline
pipeline.fit(X_train, y_train)

# Predictions and evaluation
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

# Confusion matrix and classification report
label_order = y.unique()  # Automatically detect labels
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("Confusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Execution time
execution_time = time.time() - start_time
print(f"Execution time: {execution_time:.2f} seconds")

# prompt: CALCULATE QWK FROM THE CELL ABOVE

# Assuming 'predictions' and 'y_test' are already defined from the previous code

# Calculate QWK
qwk = cohen_kappa_score(y_test, predictions, weights='quadratic')
print(f"Quadratic Weighted Kappa (QWK): {qwk}")

"""2.2.6 Classification with TF-IDF and correct passive voice"""

!pip install spacy nltk
import spacy
from spacy.matcher import Matcher
import pandas as pd
import string
import time
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# Download nltk resources
nltk.download('stopwords')
nltk.download('punkt')

stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Define function to detect correct passive voice
def correct(text):
    doc = nlp(text)
    matcher = Matcher(nlp.vocab)

    # Define the pattern for passive voice
    pattern = [
        {"POS": {"in": ["AUX"]}, "LEMMA": {"in": ["be", "am", "is", "are", "was", "were", "been"]}},
        {"POS": "ADV", "OP": "?"},  # Optional adverb
        {"TAG": "VBN"}  # Past participle
    ]
    matcher.add("PassiveVoice", [pattern])

    # Get the matches
    matches = matcher(doc)

    # Initialize valid passive count
    count = 0

    for match_id, start, end in matches:
        # Get the matched span
        span = doc[start:end]

        # Check if the span has enough tokens
        if len(span) < 2: # Changed from 3 to 2 for the simplified pattern
            continue

        # Access tokens by their position within the span
        aux_be = span[0]  # Auxiliary "be" verb
        vbn = span[-1]  # Past participle

        # Check for adjective usage, indicating non-passive voice.
        if vbn.dep_ == 'acomp':
            continue

        # If all checks pass, increment the counter
        count += 1

    return count # Return the total count of correct passive voice


# Load dataset
df = pd.read_csv('ETS_corpus_F24.csv')

# Apply error detection
df['text_correct'] = df['text'].apply(correct)

# Separate features and labels
X = df[['text', 'text_correct']]
y = df['level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessor and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text'),
        ('scaler', StandardScaler(), ['text_correct'])
    ]
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced'))
])

# Train the pipeline
pipeline.fit(X_train, y_train)

# Predictions and evaluation
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

# Confusion matrix and classification report
label_order = y.unique()  # Automatically detect labels
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("Confusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# # Execution time
execution_time = time.time() - start_time
print(f"Execution time: {execution_time:.2f} seconds")

# prompt: CALCULATE THE QWK FROM THE CELL ABOVE

# Assuming 'predictions' and 'y_test' are already defined from the previous code

# Calculate QWK
qwk = cohen_kappa_score(y_test, predictions, weights='quadratic')
print(f"Quadratic Weighted Kappa (QWK): {qwk}")

"""Average QWK"""

# prompt: calculate the average QWK from qwk's text lenght, hdd, yule's k, correct passive voice, and error passive voice

qwk_values = [0.5097676799272044, 0.48923666706839064, 0.48923666706839064, 0.3858446462285354, 0.3981155955561806]
average_qwk = sum(qwk_values) / len(qwk_values)
print(f"Average QWK: {average_qwk}")

"""ML Training

combining one by one

text length + hdd
"""

import os
import nltk
import pandas as pd
import string
import time
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, cohen_kappa_score

# Download nltk resources
nltk.download('stopwords')
nltk.download('punkt')

stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# Record start time
start_time = time.time()

# Load your dataset
df = pd.read_csv('ETS_corpus_F24.csv')

# Define text cleaning function
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = "".join([char.lower() for char in text if char not in string.punctuation])
    tokens = re.split('\W+', text)
    text = [ps.stem(word) for word in tokens if word not in stopwords]
    return " ".join(text)

# Define calculate_hdd (lexical diversity feature)
def calculate_hdd(tokens):
    return len(set(tokens)) / len(tokens) if tokens else 0

# Add linguistic features
df['text_cleaned'] = df['text'].apply(clean_text)
df['text_length'] = df['text'].apply(lambda x: len(x.split()))
df['text_HDD'] = df['text'].apply(lambda x: calculate_hdd(nltk.word_tokenize(clean_text(x))))

# Separate features and labels
X = df[['text_cleaned', 'text_length', 'text_HDD']]
y = df['level']  # 'level' is the target variable

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessor and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text_cleaned'),
        ('scaler', 'passthrough', ['text_length', 'text_HDD'])
    ]
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced'))
])

# Train the pipeline
pipeline.fit(X_train, y_train)

# Predictions and evaluation
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

# Confusion matrix and classification report
label_order = ['high', 'medium', 'low']
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Calculate Quadratic Weighted Kappa (QWK)
qwk = cohen_kappa_score(y_test, predictions, weights='quadratic')
print(f"\nQuadratic Weighted Kappa (QWK): {qwk:.4f}")

# Execution time
execution_time = time.time() - start_time
print(f"\nExecution time: {execution_time:.2f} seconds")

"""text length + hdd + yule"""

import os
import nltk
import pandas as pd
import string
import time
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, cohen_kappa_score

# Download nltk resources
nltk.download('stopwords')
nltk.download('punkt')

# Stopwords and stemmer
stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# Record start time
start_time = time.time()

# Load your dataset
df = pd.read_csv('ETS_corpus_F24.csv')

# Define text cleaning function
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = "".join([char.lower() for char in text if char not in string.punctuation])
    tokens = re.split('\W+', text)
    text = [ps.stem(word) for word in tokens if word not in stopwords]
    return " ".join(text)

# Define calculate_hdd (lexical diversity feature)
def calculate_hdd(tokens):
    return len(set(tokens)) / len(tokens) if tokens else 0

# Define calculate_yule_k (Yule's K lexical feature)
def calculate_yule_k(tokens):
    if not tokens:
        return 0
    freq_dist = nltk.FreqDist(tokens)
    n = sum(freq_dist.values())
    s1 = sum(f ** 2 for f in freq_dist.values())
    return (s1 - n) / (n ** 2) if n > 0 else 0

# Add linguistic features
df['text_cleaned'] = df['text'].apply(clean_text)
df['text_length'] = df['text'].apply(lambda x: len(x.split()))
df['text_HDD'] = df['text'].apply(lambda x: calculate_hdd(nltk.word_tokenize(clean_text(x))))
df['yule_k'] = df['text'].apply(lambda x: calculate_yule_k(nltk.word_tokenize(clean_text(x))))

# Separate features and labels
X = df[['text_cleaned', 'text_length', 'text_HDD', 'yule_k']]
y = df['level']  # Target variable

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessor and pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text_cleaned'),  # TF-IDF on cleaned text
        ('scaler', StandardScaler(), ['text_length', 'text_HDD', 'yule_k'])  # Scale numeric features
    ]
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced'))
])

# Train the pipeline
pipeline.fit(X_train, y_train)

# Predictions and evaluation
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Model Accuracy:", accuracy)

# Confusion matrix and classification report
label_order = ['high', 'medium', 'low']
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Calculate Quadratic Weighted Kappa (QWK)
qwk = cohen_kappa_score(y_test, predictions, weights='quadratic')
print(f"\nQuadratic Weighted Kappa (QWK): {qwk:.4f}")

# Execution time
execution_time = time.time

"""text length + hdd + yule + correct passive"""

!pip install spacy nltk
import os
import spacy
import nltk
import pandas as pd
import string
import time
import re
from spacy.matcher import Matcher
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, cohen_kappa_score

# Download necessary resources
nltk.download('stopwords')
nltk.download('punkt')
stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Record start time
start_time = time.time()

# Load dataset
df = pd.read_csv('ETS_corpus_F24.csv')

# ======== Feature 1: Text Cleaning ========
def clean_text(text):
    """Clean text: lowercase, remove punctuation, and stem tokens."""
    if not isinstance(text, str):
        return ""
    text = "".join([char.lower() for char in text if char not in string.punctuation])
    tokens = re.split('\W+', text)
    text = [ps.stem(word) for word in tokens if word not in stopwords]
    return " ".join(text)

# ======== Feature 2: Lexical Diversity (HDD) ========
def calculate_hdd(tokens):
    """Calculate lexical diversity HDD."""
    return len(set(tokens)) / len(tokens) if tokens else 0

# ======== Feature 3: Yule's K ========
def calculate_yule_k(tokens):
    """Calculate Yule's K measure for lexical richness."""
    if not tokens:
        return 0
    freq_dist = nltk.FreqDist(tokens)
    n = sum(freq_dist.values())
    s1 = sum(f ** 2 for f in freq_dist.values())
    return (s1 - n) / (n ** 2) if n > 0 else 0

# ======== Feature 4: Correct Passive Voice Detection ========
def detect_correct_passive(text):
    """Detect valid passive voice patterns using spaCy."""
    doc = nlp(text)
    matcher = Matcher(nlp.vocab)
    pattern = [
        {"POS": {"in": ["AUX"]}, "LEMMA": {"in": ["be", "am", "is", "are", "was", "were", "been"]}},
        {"POS": "ADV", "OP": "?"},
        {"TAG": "VBN"}
    ]
    matcher.add("PassiveVoice", [pattern])
    matches = matcher(doc)
    count = 0
    for _, start, end in matches:
        span = doc[start:end]
        if len(span) >= 2 and span[-1].dep_ != "acomp":  # Avoid adjectives
            count += 1
    return count

# ======== Apply Features to Dataset ========
df['text_cleaned'] = df['text'].apply(clean_text)
df['text_length'] = df['text'].apply(lambda x: len(x.split()))
df['text_HDD'] = df['text'].apply(lambda x: calculate_hdd(nltk.word_tokenize(clean_text(x))))
df['yule_k'] = df['text'].apply(lambda x: calculate_yule_k(nltk.word_tokenize(clean_text(x))))
df['correct_passive'] = df['text'].apply(detect_correct_passive)

# ======== Prepare Features and Labels ========
X = df[['text_cleaned', 'text_length', 'text_HDD', 'yule_k', 'correct_passive']]
y = df['level']  # Target variable

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ======== Preprocessor and Pipeline ========
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text_cleaned'),  # TF-IDF on cleaned text
        ('scaler', StandardScaler(), ['text_length', 'text_HDD', 'yule_k', 'correct_passive'])  # Scale numeric features
    ]
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced'))
])

# ======== Train and Evaluate ========
pipeline.fit(X_train, y_train)
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)

print("Model Accuracy:", accuracy)

# Confusion Matrix and Report
label_order = ['high', 'medium', 'low']
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Calculate Quadratic Weighted Kappa (QWK)
qwk = cohen_kappa_score(y_test, predictions, weights='quadratic')
print(f"\nQuadratic Weighted Kappa (QWK): {qwk:.4f}")

# Execution Time
execution_time = time.time() - start_time
print(f"\nExecution time: {execution_time:.2f} seconds")

!pip install spacy nltk
import os
import spacy
import nltk
import pandas as pd
import string
import time
import re
from spacy.matcher import Matcher
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, cohen_kappa_score

# Download necessary resources
nltk.download('stopwords')
nltk.download('punkt')
stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Record start time
start_time = time.time()

# Load dataset
df = pd.read_csv('ETS_corpus_F24.csv')

# ======== Feature 1: Text Cleaning ========
def clean_text(text):
    """Clean text: lowercase, remove punctuation, and stem tokens."""
    if not isinstance(text, str):
        return ""
    text = "".join([char.lower() for char in text if char not in string.punctuation])
    tokens = re.split('\W+', text)
    text = [ps.stem(word) for word in tokens if word not in stopwords]
    return " ".join(text)

# ======== Feature 2: Lexical Diversity (HDD) ========
def calculate_hdd(tokens):
    """Calculate lexical diversity HDD."""
    return len(set(tokens)) / len(tokens) if tokens else 0

# ======== Feature 3: Yule's K ========
def calculate_yule_k(tokens):
    """Calculate Yule's K measure for lexical richness."""
    if not tokens:
        return 0
    freq_dist = nltk.FreqDist(tokens)
    n = sum(freq_dist.values())
    s1 = sum(f ** 2 for f in freq_dist.values())
    return (s1 - n) / (n ** 2) if n > 0 else 0

# ======== Feature 4: Correct Passive Voice Detection ========
def detect_correct_passive(text):
    """Detect valid passive voice patterns using spaCy."""
    doc = nlp(text)
    matcher = Matcher(nlp.vocab)
    pattern = [
        {"POS": {"in": ["AUX"]}, "LEMMA": {"in": ["be", "am", "is", "are", "was", "were", "been"]}},
        {"POS": "ADV", "OP": "?"},
        {"TAG": "VBN"}
    ]
    matcher.add("PassiveVoice", [pattern])
    matches = matcher(doc)
    return len(matches)

# ======== Feature 5: Passive Voice Error Detection ========
def error_detection(text):
    """Detect passive voice errors."""
    if not text:
        return 0
    doc = nlp(text)
    matcher = Matcher(nlp.vocab)
    pattern = [
        {"POS": {"in": ["AUX"]}, "LEMMA": {"in": ["will", "would", "can", "could", "may", "might", "must", "shall", "should"]}, "OP": "?"},
        {"POS": {"in": ["AUX"]}, "LEMMA": {"in": ["be", "am", "is", "are", "was", "were", "been"]}},
        {"POS": "ADV", "OP": "?"},
        {"TAG": "VBN"}
    ]
    matcher.add("PassiveVoice", [pattern])
    return len(matcher(doc))

# ======== Apply Features to Dataset ========
df['text_cleaned'] = df['text'].apply(clean_text)
df['text_length'] = df['text'].apply(lambda x: len(x.split()))
df['text_HDD'] = df['text'].apply(lambda x: calculate_hdd(nltk.word_tokenize(clean_text(x))))
df['yule_k'] = df['text'].apply(lambda x: calculate_yule_k(nltk.word_tokenize(clean_text(x))))
df['correct_passive'] = df['text'].apply(detect_correct_passive)
df['text_error'] = df['text'].apply(error_detection)

# ======== Prepare Features and Labels ========
X = df[['text_cleaned', 'text_length', 'text_HDD', 'yule_k', 'correct_passive', 'text_error']]
y = df['level']  # Target variable

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ======== Preprocessor and Pipeline ========
preprocessor = ColumnTransformer(
    transformers=[
        ('tfidf', TfidfVectorizer(), 'text_cleaned'),  # TF-IDF on cleaned text
        ('scaler', StandardScaler(), ['text_length', 'text_HDD', 'yule_k', 'correct_passive', 'text_error'])  # Scale numeric features
    ]
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced'))
])

# ======== Train and Evaluate ========
pipeline.fit(X_train, y_train)
predictions = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, predictions)

print("Model Accuracy:", accuracy)

# Confusion Matrix and Report
label_order = ['high', 'medium', 'low']
conf_matrix = confusion_matrix(y_test, predictions, labels=label_order)
class_report = classification_report(y_test, predictions, labels=label_order, target_names=label_order)

print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

# Calculate Quadratic Weighted Kappa (QWK)
qwk = cohen_kappa_score(y_test, predictions, weights='quadratic')
print(f"\nQuadratic Weighted Kappa (QWK): {qwk:.4f}")

# Execution Time
execution_time = time.time() - start_time
print(f"\nExecution time: {execution_time:.2f} seconds")

import pandas as pd
import nltk
import string
import math
from collections import Counter
import spacy
from spacy.matcher import Matcher

# Ensure necessary downloads
nltk.download('punkt')
nltk.download('stopwords')

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Define text cleaning function
def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = "".join([char for char in text if char not in string.punctuation])  # Remove punctuation
    return text

# HDD calculation
def calculate_hdd(tokens):
    if not tokens:
        return 0
    n = len(tokens)
    freq_dist = Counter(tokens)
    hdd = 0
    for token, freq in freq_dist.items():
        hdd += (1 - math.pow((n - freq) / n, freq)) / n
    return hdd

# Yule's K calculation
def calculate_yule_k(tokens):
    if not tokens:
        return 0
    freq_dist = Counter(tokens)
    n = sum(freq_dist.values())  # Total words
    s1 = sum(f ** 2 for f in freq_dist.values())  # Sum of squared frequencies
    if n == 0:
        return 0
    return (s1 - n) / (n ** 2)

# Passive voice error detection
def error(text):
    if not text:
        return 0
    doc = nlp(text)
    matcher = Matcher(nlp.vocab)
    pattern = [
        {"POS": {"IN": ["AUX"]}, "LEMMA": {"IN": ["be", "am", "is", "are", "was", "were", "been"]}},
        {"POS": "ADV", "OP": "?"},
        {"TAG": "VBN"}
    ]
    matcher.add("PassiveVoice", [pattern])
    matches = matcher(doc)
    return len(matches)

# Correct passive voice usage detection
def correct(text):
    if not text:
        return 0
    doc = nlp(text)
    matcher = Matcher(nlp.vocab)
    pattern = [
        {"POS": {"IN": ["AUX"]}, "LEMMA": {"IN": ["be", "am", "is", "are", "was", "were", "been"]}},
        {"POS": "ADV", "OP": "?"},
        {"TAG": "VBN"}
    ]
    matcher.add("PassiveVoice", [pattern])
    matches = matcher(doc)
    return len(matches)

# Load dataset
try:
    df = pd.read_csv("ETS_corpus_F24.csv")
except FileNotFoundError:
    print("Error: The file 'ETS_corpus_F24.csv' was not found.")
    exit()

# Ensure text column exists and preprocess text
if 'text' not in df.columns:
    print("Error: The dataset does not contain a 'text' column.")
    exit()

df['text'] = df['text'].fillna('').astype(str)

# Feature calculations
df['text_length'] = df['text'].apply(lambda x: len(x.split()))  # Text length
df['HDD'] = df['text'].apply(lambda x: calculate_hdd(nltk.word_tokenize(clean_text(x))))  # HDD
df['Yule_K'] = df['text'].apply(lambda x: calculate_yule_k(nltk.word_tokenize(clean_text(x))))  # Yule's K
df['Passive_Error'] = df['text'].apply(error)  # Passive voice errors
df['Passive_Correct'] = df['text'].apply(correct)  # Correct passive usage

# Display the first few rows of the DataFrame
print(df.head())

# Optionally, save the processed dataset to a CSV file for further use
df.to_csv("processed_dataset.csv", index=False)
print("Processed dataset saved to 'processed_dataset.csv'")

"""prepare for model training"""

# Features (X) and Labels (y)
X = df[['text_length', 'HDD', 'Yule_K', 'Passive_Error', 'Passive_Correct']]
y = df['level']  # Target labels (e.g., low, medium, high)

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""random forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
import numpy as np
import pandas as pd

# Quadratic Weighted Kappa Function
def quadratic_weighted_kappa(y_true, y_pred):
    y_true = np.asarray(y_true, dtype=int)
    y_pred = np.asarray(y_pred, dtype=int)
    min_rating = min(np.min(y_true), np.min (y_pred))
    max_rating = max(np.max(y_true), np.max(y_pred))
    num_ratings = max_rating - min_rating + 1

    conf_matrix = np.zeros((num_ratings, num_ratings), dtype=float)
    for true, pred in zip(y_true, y_pred):
        conf_matrix[true - min_rating, pred - min_rating] += 1

    weights = np.zeros((num_ratings, num_ratings), dtype=float)
    for i in range(num_ratings):
        for j in range(num_ratings):
            weights[i, j] = ((i - j) ** 2) / ((num_ratings - 1) ** 2)

    hist_true = np.histogram(y_true, bins=np.arange(min_rating, max_rating + 2))[0]
    hist_pred = np.histogram(y_pred, bins=np.arange(min_rating, max_rating + 2))[0]

    expected_matrix = np.outer(hist_true, hist_pred) / len(y_true)
    observed = np.sum(weights * conf_matrix)
    expected = np.sum(weights * expected_matrix)

    return 1 - (observed / expected)

# Apply LabelEncoder before training
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Train Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train_encoded)

# Make predictions
y_pred_encoded = rf.predict(X_test)

# Decode predictions back to original labels for evaluation
y_pred = label_encoder.inverse_transform(y_pred_encoded)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Calculate QWK
qwk_score = quadratic_weighted_kappa(y_test_encoded, y_pred_encoded)
print(f"\nQuadratic Weighted Kappa (QWK): {qwk_score:.3f}")

# Display the first 5 rows of the processed dataset
processed_data = X_test.copy()  # Assuming X_test already includes the required features
processed_data['text_length'] = X_test['text_length']
processed_data['HDD'] = X_test['HDD']
processed_data['Yule_K'] = X_test['Yule_K']
processed_data['Passive_Error'] = X_test['Passive_Error']
processed_data['Passive_Correct'] = X_test['Passive_Correct']


# Print the processed dataset to the screen
print("\nProcessed Dataset:")
print(processed_data.head())

print(sklearn.__version__)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV
import numpy as np
import pandas as pd

# Quadratic Weighted Kappa Function
def quadratic_weighted_kappa(y_true, y_pred):
    y_true = np.asarray(y_true, dtype=int)
    y_pred = np.asarray(y_pred, dtype=int)
    min_rating = min(np.min(y_true), np.min(y_pred))
    max_rating = max(np.max(y_true), np.max(y_pred))
    num_ratings = max_rating - min_rating + 1

    conf_matrix = np.zeros((num_ratings, num_ratings), dtype=float)
    for true, pred in zip(y_true, y_pred):
        conf_matrix[true - min_rating, pred - min_rating] += 1

    weights = np.zeros((num_ratings, num_ratings), dtype=float)
    for i in range(num_ratings):
        for j in range(num_ratings):
            weights[i, j] = ((i - j) ** 2) / ((num_ratings - 1) ** 2)

    hist_true = np.histogram(y_true, bins=np.arange(min_rating, max_rating + 2))[0]
    hist_pred = np.histogram(y_pred, bins=np.arange(min_rating, max_rating + 2))[0]

    expected_matrix = np.outer(hist_true, hist_pred) / len(y_true)
    observed = np.sum(weights * conf_matrix)
    expected = np.sum(weights * expected_matrix)

    return 1 - (observed / expected)

# Apply LabelEncoder before training
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Hyperparameter tuning using GridSearchCV
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'random_state': [42]
}

rf = RandomForestClassifier()
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1)
grid_search.fit(X_train, y_train_encoded)

# Best parameters from grid search
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Train Random Forest with the best hyperparameters
rf_best = RandomForestClassifier(**best_params)
rf_best.fit(X_train, y_train_encoded)

# Make predictions
y_pred_encoded = rf_best.predict(X_test)

# Decode predictions back to original labels for evaluation
y_pred = label_encoder.inverse_transform(y_pred_encoded)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Calculate QWK
qwk_score = quadratic_weighted_kappa(y_test_encoded, y_pred_encoded)
print(f"\nQuadratic Weighted Kappa (QWK): {qwk_score:.3f}")

# Display the first 5 rows of the processed dataset
processed_data = X_test.copy()  # Assuming X_test already includes the required features
processed_data['text_length'] = X_test['text_length']
processed_data['HDD'] = X_test['HDD']
processed_data['Yule_K'] = X_test['Yule_K']
processed_data['Passive_Error'] = X_test['Passive_Error']
processed_data['Passive_Correct'] = X_test['Passive_Correct']

# Print the processed dataset to the screen
print("\nProcessed Dataset:")
print(processed_data.head())



# prompt: print the table for the classification report above

from sklearn.metrics import classification_report

# Assuming 'y_test' and 'y_pred' are defined from your previous code
# Replace with your actual y_test and y_pred
# Example:
# y_test = [...]  # Your true labels
# y_pred = [...]  # Your predicted labels

# Calculate and print the classification report
class_report = classification_report(y_test, y_pred, labels=['high', 'medium', 'low'], target_names=['high', 'medium', 'low'])
class_report

processed_data['Y_value'] = y_test
processed_data

# prompt: CALCULATE THE AVERAGE KAPPA FROM THE CELL ABOVE

# Assuming 'qwk_score' is the variable holding the calculated QWK value.
# If it's not available, you'll need to calculate it first using the provided code.

print(f"Average Kappa: {qwk_score:.3f}")

"""SVM"""

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib

# Features and labels
X = df[['text_length', 'HDD', 'Yule_K', 'Passive_Error', 'Passive_Correct']]
y = df['level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train SVM
svm_model = SVC(kernel='linear', C=1, random_state=42)
svm_model.fit(X_train_scaled, y_train)

# Predictions
y_pred = svm_model.predict(X_test_scaled)

# Evaluation
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Save the model
joblib.dump(svm_model, 'svm_model.pkl')
print("Model saved as 'svm_model.pkl'")

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import GridSearchCV, train_test_split
import numpy as np
import pandas as pd
import joblib

# Quadratic Weighted Kappa Function
def quadratic_weighted_kappa(y_true, y_pred):
    y_true = np.asarray(y_true, dtype=int)
    y_pred = np.asarray(y_pred, dtype=int)
    min_rating = min(np.min(y_true), np.min(y_pred))
    max_rating = max(np.max(y_true), np.max(y_pred))
    num_ratings = max_rating - min_rating + 1

    conf_matrix = np.zeros((num_ratings, num_ratings), dtype=float)
    for true, pred in zip(y_true, y_pred):
        conf_matrix[true - min_rating, pred - min_rating] += 1

    weights = np.zeros((num_ratings, num_ratings), dtype=float)
    for i in range(num_ratings):
        for j in range(num_ratings):
            weights[i, j] = ((i - j) ** 2) / ((num_ratings - 1) ** 2)

    hist_true = np.histogram(y_true, bins=np.arange(min_rating, max_rating + 2))[0]
    hist_pred = np.histogram(y_pred, bins=np.arange(min_rating, max_rating + 2))[0]

    expected_matrix = np.outer(hist_true, hist_pred) / len(y_true)
    observed = np.sum(weights * conf_matrix)
    expected = np.sum(weights * expected_matrix)

    return 1 - (observed / expected)

# Features and labels
X = df[['text_length', 'HDD', 'Yule_K', 'Passive_Error', 'Passive_Correct']]
y = df['level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply LabelEncoder before training
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Hyperparameter tuning using GridSearchCV for SVM
param_grid_svm = {
    'kernel': ['linear', 'rbf'],
    'C': [0.1, 1, 10],
    'random_state': [42]
}

svm = SVC()
grid_search_svm = GridSearchCV(estimator=svm, param_grid=param_grid_svm, scoring='accuracy', cv=3, verbose=1)
grid_search_svm.fit(X_train_scaled, y_train)

# Best parameters from grid search for SVM
best_params_svm = grid_search_svm.best_params_
print("Best Hyperparameters for SVM:", best_params_svm)

# Train SVM with the best hyperparameters
svm_best = SVC(**best_params_svm)
svm_best.fit(X_train_scaled, y_train)

# Predictions for SVM
y_pred_svm = svm_best.predict(X_test_scaled)

# Evaluate SVM
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print(f"SVM Model Accuracy: {accuracy_svm:.2f}")
print("\nSVM Classification Report:\n", classification_report(y_test, y_pred_svm))

# Save the best SVM model
joblib.dump(svm_best, 'svm_best_model.pkl')
print("SVM model saved as 'svm_best_model.pkl'")

# Display the first 5 rows of the processed dataset
processed_data = X_test.copy()  # Assuming X_test already includes the required features
processed_data['text_length'] = X_test['text_length']
processed_data['HDD'] = X_test['HDD']
processed_data['Yule_K'] = X_test['Yule_K']
processed_data['Passive_Error'] = X_test['Passive_Error']
processed_data['Passive_Correct'] = X_test['Passive_Correct']

# Print the processed dataset to the screen
print("\nProcessed Dataset:")
print(processed_data.head())

processed_data['Y_value'] = y_test
processed_data

# prompt: CALCULATE THE QWK FROM THE CELL ABOVE

# Assuming 'y_test' and 'y_pred' are available from the previous code
from sklearn.metrics import cohen_kappa_score

# Ensure y_test and y_pred are numpy arrays, fit LabelEncoder to y_test if needed
# Re-initialize the LabelEncoder to avoid previous fits
label_encoder = LabelEncoder()

# Fit the encoder to the combined labels to handle all cases
label_encoder.fit(np.concatenate((y_test, y_pred)))

y_test_encoded = label_encoder.transform(y_test)
y_pred_encoded = label_encoder.transform(y_pred)


qwk = cohen_kappa_score(y_test_encoded, y_pred_encoded, weights='quadratic')
print(f"Quadratic Weighted Kappa (QWK): {qwk}")

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import GridSearchCV, train_test_split
import numpy as np
import pandas as pd
import joblib

# Features and labels
X = df[['text_length', 'HDD', 'Yule_K', 'Passive_Error', 'Passive_Correct']]
y = df['level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Hyperparameter tuning using GridSearchCV for Logistic Regression
param_grid_logreg = {
    'penalty': ['l1', 'l2'],
    'C': [0.1, 1, 10],
    'solver': ['liblinear'],
    'class_weight': ['balanced', None]
}

logreg = LogisticRegression(random_state=42)
grid_search_logreg = GridSearchCV(estimator=logreg, param_grid=param_grid_logreg, scoring='accuracy', cv=3, verbose=1)
grid_search_logreg.fit(X_train_scaled, y_train)

# Best parameters from grid search for Logistic Regression
best_params_logreg = grid_search_logreg.best_params_
print("Best Hyperparameters for Logistic Regression:", best_params_logreg)

# Train Logistic Regression with the best hyperparameters
logreg_best = LogisticRegression(**best_params_logreg, random_state=42)
logreg_best.fit(X_train_scaled, y_train)

# Make predictions for Logistic Regression
y_pred_logreg = logreg_best.predict(X_test_scaled)

# Evaluate Logistic Regression
accuracy_logreg = accuracy_score(y_test, y_pred_logreg)
print(f"Logistic Regression Model Accuracy: {accuracy_logreg:.2f}")
print("\nLogistic Regression Classification Report:\n", classification_report(y_test, y_pred_logreg))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_logreg))

# Save the best Logistic Regression model
joblib.dump(logreg_best, 'logistic_regression_model.pkl')
print("Logistic Regression model saved as 'logistic_regression_model.pkl'")

# Display the first 5 rows of the processed dataset
processed_data = X_test.copy()  # Assuming X_test already includes the required features
processed_data['text_length'] = X_test['text_length']
processed_data['HDD'] = X_test['HDD']
processed_data['Yule_K'] = X_test['Yule_K']
processed_data['Passive_Error'] = X_test['Passive_Error']
processed_data['Passive_Correct'] = X_test['Passive_Correct']

# Print the processed dataset to the screen
print("\nProcessed Dataset:")
print(processed_data.head())

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib

# Features and target variable
X = df[['text_length', 'HDD', 'Yule_K', 'Passive_Error', 'Passive_Correct']]
y = df['level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],        # Test different regularization strengths
    'solver': ['liblinear', 'saga'],     # Try different solvers
    'class_weight': ['balanced', None]  # Compare handling of imbalanced data
}

# Create a LogisticRegression model
logreg = LogisticRegression(random_state=42)

# Set up GridSearchCV
grid_search = GridSearchCV(
    estimator=logreg,
    param_grid=param_grid,
    scoring='accuracy',    # Use accuracy as the metric
    cv=5,                  # 5-fold cross-validation
    n_jobs=-1,             # Use all available CPU cores
    verbose=2              # Print progress
)

# Perform grid search
grid_search.fit(X_train_scaled, y_train)

# Print the best parameters and best score
print("Best Parameters:", grid_search.best_params_)
print("Best Cross-Validation Accuracy:", grid_search.best_score_)

# Train the final model with the best parameters
best_model = grid_search.best_estimator_
best_model.fit(X_train_scaled, y_train)

# Evaluate the final model
y_pred = best_model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Save the final model
joblib.dump(best_model, 'logistic_regression_best_model.pkl')
print("Model saved as 'logistic_regression_best_model.pkl'")

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import numpy as np
import joblib

# Quadratic Weighted Kappa Function
def quadratic_weighted_kappa(y_true, y_pred):
    """
    Calculate the Quadratic Weighted Kappa (QWK) score between true and predicted labels.

    Args:
        y_true (list or array): True labels (e.g., human-graded scores).
        y_pred (list or array): Predicted labels (e.g., model-graded scores).

    Returns:
        float: Quadratic Weighted Kappa score.
    """
    y_true = np.asarray(y_true, dtype=int)
    y_pred = np.asarray(y_pred, dtype=int)
    min_rating = min(np.min(y_true), np.min(y_pred))
    max_rating = max(np.max(y_true), np.max(y_pred))
    num_ratings = max_rating - min_rating + 1

    conf_matrix = np.zeros((num_ratings, num_ratings), dtype=float)
    for true, pred in zip(y_true, y_pred):
        conf_matrix[true - min_rating, pred - min_rating] += 1

    weights = np.zeros((num_ratings, num_ratings), dtype=float)
    for i in range(num_ratings):
        for j in range(num_ratings):
            weights[i, j] = ((i - j) ** 2) / ((num_ratings - 1) ** 2)

    hist_true = np.histogram(y_true, bins=np.arange(min_rating, max_rating + 2))[0]
    hist_pred = np.histogram(y_pred, bins=np.arange(min_rating, max_rating + 2))[0]

    expected_matrix = np.outer(hist_true, hist_pred) / len(y_true)
    observed = np.sum(weights * conf_matrix)
    expected = np.sum(weights * expected_matrix)

    return 1 - (observed / expected)

# Features and target variable
X = df[['text_length', 'HDD', 'Yule_K', 'Passive_Error', 'Passive_Correct']]
y = df['level']

# Encode target variable if labels are categorical
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train Logistic Regression
logreg_model = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42)
logreg_model.fit(X_train_scaled, y_train)

# Make predictions
y_pred = logreg_model.predict(X_test_scaled)

# Calculate QWK
qwk_score = quadratic_weighted_kappa(y_test, y_pred)
print(f"\nQuadratic Weighted Kappa (QWK): {qwk_score:.3f}")

# Save the model
joblib.dump(logreg_model, 'logistic_regression_model.pkl')
print("Model saved as 'logistic_regression_model.pkl'")

processed_data['Y_value'] = y_test
processed_data

# prompt: CALCULATE THE QWK FROM THE CELL ABOVE

# Assuming 'y_test' and 'y_pred' are available from the previous code
# and represent the true and predicted labels, respectively.

# Ensure y_test and y_pred are numpy arrays and have consistent encoding.
# Re-initialize the LabelEncoder to avoid previous fits
label_encoder = LabelEncoder()

# Fit the encoder to the combined labels to handle all cases
label_encoder.fit(np.concatenate((y_test, y_pred)))

y_test_encoded = label_encoder.transform(y_test)
y_pred_encoded = label_encoder.transform(y_pred)

qwk = cohen_kappa_score(y_test_encoded, y_pred_encoded, weights='quadratic')
print(f"Quadratic Weighted Kappa (QWK): {qwk}")

import pandas as pd

# Data: Results of models
results = {
    "Model": [
        "Logistic Regression (Default)",
        "Logistic Regression (Tuned)",
        "Random Forest (Default)",
        "Random Forest (Tuned)",
        "SVM (Default)",
        "SVM (Tuned)"
    ],
    "Accuracy": [0.64, 0.66, 0.63, 0.65, 0.65, 0.66],
    "QWK": [0.333, 0.333, 0.278, 0.309, 0.313, 0.314]
}

# Convert to DataFrame
results_df = pd.DataFrame(results)

# Highlight the best model based on QWK
results_df['Best'] = results_df['QWK'] == results_df['QWK'].max()

# Display the DataFrame
print(results_df)

